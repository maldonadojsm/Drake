#!/usr/bin/env python
# Created by zahza at 3/11/20
import speech_recognition as sr
import playsound as ps  # to play saved mp3 file
import os
import socket
import tqdm
from gtts import gTTS  # google text to speech
from google.cloud import speech_v1
from google.cloud.speech_v1 import enums
import io
import dialogflow_v2 as dialogflow

SEPARATOR = "<SEPARATOR>"
BUFFER_SIZE = 4096
session_id = "123456"
project_id = "atomic-nation-268705"


class AudioStream:
	""" The AudioStream class records (FLAC) files and plays (MP3) audio. """

	def __init__(self, recording_duration):
		self.recording_duration = recording_duration

	def record_voice(self):
		"""
		Record user's voice.
		"""
		r = sr.Recognizer()
		with sr.Microphone() as source:
			print("Speak...")
			audio = r.listen(source, phrase_time_limit=self.recording_duration)
			print("Stop.")

			# Generate FLAC file dat
			self.write_audio_file(audio)

		voice_recording = self.parse_audio()

		return voice_recording

	def parse_audio(self):
		"""
		Transcribe a short audio file using synchronous speech recognition

		Args:
		local_file_path Path to local audio file, e.g. /path/audio.wav
		"""
		client = speech_v1.SpeechClient()
		local_file_path = "voice.flac"
		# local_file_path = 'resources/brooklyn_bridge.raw'

		# The language of the supplied audio
		language_code = "en-US"

		# Sample rate in Hertz of the audio data sent
		sample_rate_hertz = 16000

		# Encoding of audio data sent. This sample sets this explicitly.
		# This field is optional for FLAC and WAV audio formats.
		encoding = enums.RecognitionConfig.AudioEncoding.FLAC
		config = {
			"language_code": language_code,
			# "sample_rate_hertz": sample_rate_hertz,
			"encoding": encoding,
		}
		with io.open(local_file_path, "rb") as f:
			content = f.read()
		audio = {"content": content}

		response = client.recognize(config, audio)
		for result in response.results:
			# First alternative is the most probable result
			alternative = result.alternatives[0]

			return u"{}".format(alternative.transcript)

	@staticmethod
	def speak_text(text: str):
		"""
		Transforms string text into speech using Google's Text to Speech API.
		@param text: Text in string format
		"""
		spoken_text = gTTS(text=text, lang='en', slow=False)
		spoken_text.save("spoken_text.mp3")
		file_name = "spoken_text.mp3"
		spoken_text.save(file_name)

		# playsound package is used to play the same file.
		ps.playsound(file_name, True)
		os.remove(file_name)

	def write_audio_file(self, audio_data: object):
		"""
		Generate .flac audio file from FLAC data.
		@param audio_data: audio flac data generated by Microphone class
		"""
		audio_file = audio_data.get_flac_data(convert_rate=None if 8000 <= audio_data.sample_rate <= 48000
		else max(8000, min(audio_data.sample_rate, 48000)), convert_width=2)

		with open("voice.flac", 'wb') as f:
			f.write(audio_file)  # Saves File

	@staticmethod
	def play_audio_file(audio_file):
		"""
		Plays MP3 File
		@param audio_file: Audio File (MP3)
		"""
		ps.playsound(audio_file, True)
		os.remove(os.path.abspath(audio_file))

	@staticmethod
	def send_audio_file(server_ip, server_port):
		"""
		Send audio file to server using sockets
		"""
		# Audio Filepath
		payload = "voice.flac"
		# Audio File Size
		payload_size = os.path.getsize(payload)

		# create client socket
		s = socket.socket()

		# connect to server
		s.connect((server_ip, server_port))
		# send filename and file size
		s.send(f"{payload}{SEPARATOR}{payload_size}".encode())

		# create upload progress bar
		progress = tqdm.tqdm(range(payload_size), f"Sending {os.path.basename(payload)}", unit="B", unit_scale=True,
							 unit_divisor=1024)
		# start upload file process
		with open(payload, "rb") as f:
			for _ in progress:

				# read bytes from file
				read_bytes = f.read(BUFFER_SIZE)
				# File upload complete
				if not read_bytes:
					break
				# send file to server
				s.sendall(read_bytes)

				# update upload progress bar
				progress.update(len(read_bytes))

		# close socket

		s.close()

	@staticmethod
	def detect_intent_texts(text, project_id=project_id, session_id=session_id, language_code='en-US'):
		"""Returns the result of detect intent with texts as inputs.
		Using the same `session_id` between requests allows continuation
		of the conversation."""
		session_client = dialogflow.SessionsClient()

		session = session_client.session_path(project_id, session_id)

		text_input = dialogflow.types.TextInput(
			text=text, language_code=language_code)

		query_input = dialogflow.types.QueryInput(text=text_input)

		response = session_client.detect_intent(
			session=session, query_input=query_input)

		return '{}\n'.format(
			response.query_result.fulfillment_text)
